{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training for the Simple pendulum inverse equilibrium\n",
    "\n",
    "In theory it could be solved by PID, but let's use big weapon to solve these problem\n",
    "\n",
    "## Environment configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from function.Dynamics_modeling import *\n",
    "from function.Euler_lagrange import *\n",
    "from function.Render import *\n",
    "from function.Catalog_gen import *\n",
    "\n",
    "from function.ray_env_creator import *\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "import ray\n",
    "from ray import tune,train\n",
    "from ray.rllib.algorithms.ppo import PPO\n",
    "\n",
    "import pprint\n",
    "\n",
    "# Single pendulum exclusive.....\n",
    "\n",
    "# Initialisation du modèle théorique\n",
    "\n",
    "t = sp.symbols(\"t\")\n",
    "\n",
    "CoordNumb = 1\n",
    "\n",
    "Symb = Symbol_Matrix_g(CoordNumb,t)\n",
    "\n",
    "theta = Symb[1,0]\n",
    "theta_d = Symb[2,0]\n",
    "theta_dd = Symb[3,0]\n",
    "\n",
    "m, l, g = sp.symbols(\"m l g\")\n",
    "\n",
    "L = 0.2\n",
    "Substitution = {\"g\": 9.81, \"l\": L, \"m\": 0.1}\n",
    "\n",
    "Time_end = 14\n",
    "\n",
    "#----------------External Forces--------------------\n",
    "\n",
    "F_ext_time = np.array([0, 2, 4, 6, 8, Time_end])\n",
    "F_ext_Value = np.array([[0, 1, -1, 1, 1, -1]]) * 0.0  # De la forme (k,...)\n",
    "\n",
    "F_ext_func = interpolate.CubicSpline(F_ext_time, F_ext_Value, axis=1)\n",
    "# ---------------------------\n",
    "\n",
    "Y0 = np.array([[2, 0]])  # De la forme (k,2)\n",
    "\n",
    "L_System = m*l**2/2*theta_d**2+sp.cos(theta)*l*m*g\n",
    "\n",
    "Acc_func,_ = Lagrangian_to_Acc_func(L_System, Symb, t, Substitution, fluid_f=[-0.008])\n",
    "\n",
    "Dynamics_system = Dynamics_f_extf(Acc_func)\n",
    "\n",
    "EnvConfig = {\n",
    "    \"coord_numb\": CoordNumb,\n",
    "    \"target\":np.array([np.pi,0]),\n",
    "    \"dynamics_function_h\":Dynamics_system,\n",
    "    \"h\":0.02\n",
    "}\n",
    "\n",
    "#ray.shutdown()\n",
    "#ray.init(num_gpus=2,num_cpus=1,dashboard_host=\"0.0.0.0\")\n",
    "#ray.init(num_gpus=3,num_cpus=0,dashboard_host=\"0.0.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Know we can do the training for our algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do more training for our policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "my_new_ppo = Algorithm.from_checkpoint(\"/home/eymeric/ray_checkpoints/checkpoint_exp2_0003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = (\n",
    "    PPOConfig().environment(\n",
    "        # Env class to use (here: our gym.Env sub-class from above).\n",
    "        env=MyFunctionEnv,\n",
    "        env_config=EnvConfig,\n",
    "    )\n",
    "    .framework(\"torch\")\n",
    "    # Parallelize environment rollouts.\n",
    "    .env_runners(num_env_runners=10,num_cpus_per_env_runner=1, num_gpus_per_env_runner=1 / 16)\n",
    "    .training(lr=0.0001,gamma=0.99,entropy_coeff=0.0005)\n",
    ")\n",
    "my_new_ppo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training\n",
    "expname = \"checkpoint_exp2_0004\"\n",
    "\n",
    "for i in range(40):\n",
    "    results = my_new_ppo.train()\n",
    "    print(f\"Iter: {i}; avg. return={results['env_runners']['episode_return_mean']}\")\n",
    "\n",
    "    if i%5 == 4:\n",
    "        save_result = my_new_ppo.save(\"/home/eymeric/ray_checkpoints/\"+expname+\"_\"+str(i))\n",
    "        path_to_checkpoint = save_result.checkpoint.path\n",
    "        print(\n",
    "            \"An Algorithm checkpoint has been created inside directory: \"\n",
    "            f\"'{path_to_checkpoint}'.\"\n",
    "        )\n",
    "    \n",
    "\n",
    "save_result = my_new_ppo.save(\"/home/eymeric/ray_checkpoints/\"+expname)\n",
    "path_to_checkpoint = save_result.checkpoint.path\n",
    "print(\n",
    "    \"An Algorithm checkpoint has been created inside directory: \"\n",
    "    f\"'{path_to_checkpoint}'.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "stop = False\n",
    "Environment = MyFunctionEnv(EnvConfig)\n",
    "\n",
    "my_new_ppo = Algorithm.from_checkpoint(\"/tmp/tmpoonj8141\")\n",
    "\n",
    "\n",
    "while not stop:\n",
    "\n",
    "    action = my_new_ppo.compute_single_action(Environment.state)\n",
    "\n",
    "    state, reward, stop, truncated,_ = Environment.step(action)\n",
    "\n",
    "    print(state, reward, action, stop, truncated)\n",
    "\n",
    "    Environment.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
